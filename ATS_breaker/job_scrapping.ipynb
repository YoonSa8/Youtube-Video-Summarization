{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page source saved to page_source.html\n"
     ]
    }
   ],
   "source": [
    "#open linkedin job search page\n",
    "driver = webdriver.Chrome()\n",
    "job_search_url = \"https://www.linkedin.com/jobs/search/?keywords=data%20scientist\"\n",
    "driver.get(job_search_url)\n",
    "time.sleep(10)\n",
    "html_source = driver.page_source  # Get the full HTML of the page\n",
    "\n",
    "# Save it to a file for better viewing\n",
    "with open(\"page_source.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_source)\n",
    "\n",
    "print(\"Page source saved to page_source.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page source saved to single_job_page.html\n"
     ]
    }
   ],
   "source": [
    "#job page html save \n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "job_search_url = \"https://www.linkedin.com/jobs/search/?keywords=data%20scientist\"\n",
    "driver.get(job_search_url)\n",
    "time.sleep(10) \n",
    "\n",
    "driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "try:\n",
    "    first_job = driver.find_element(By.CLASS_NAME, 'base-search-card')\n",
    "    first_job.click()\n",
    "    time.sleep(5)  \n",
    "    job_html = driver.page_source\n",
    "\n",
    "    # Save to file\n",
    "    with open(\"single_job_page.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(job_html)\n",
    "\n",
    "    print(\"Page source saved to single_job_page.html\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Job Title': 'Machine Learning Engineer', 'Company': 'N/A', 'Description': \"Role - Machine learning developer Fulltime Perm position – Based in the NYC office. Must be onsite 4 days a week. About the job OVERVIEW: Machine learning developers at the client work closely with researchers to creatively apply their knowledge of machine learning and software engineering to design, build, and maintain systems for high-performance, large-scale knowledge discovery in financial data. Machine learning developers could be part of an inclusive, collaborative, and engaging working environment. WHAT YOU'LL DO DAY-TO-DAY: Specific responsibilities include designing, implementing, testing, and documenting modules for all stages of the pipeline from data to predictions, assembling these modules into end-to-end systems, and interacting with researchers to achieve highly productive experimentation, model construction, and validation. WHO WE’RE LOOKING FOR: Successful candidates will have a strong knowledge of software engineering, machine learning, and open-source machine learning ecosystems. A track record of building and applying high-performance machine learning systems is desired While an impressive record of academic achievement is a plus, we welcome outstanding candidates from diverse academic disciplines and backgrounds.\"}\n"
     ]
    }
   ],
   "source": [
    "#one job only\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open LinkedIn job search page\n",
    "job_search_url = \"https://www.linkedin.com/jobs/search/?keywords=data%20scientist\"\n",
    "driver.get(job_search_url)\n",
    "time.sleep(10)  # Wait for initial page load\n",
    "\n",
    "# Scroll to load jobs\n",
    "for _ in range(3):\n",
    "    driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(3)\n",
    "\n",
    "# Find and click the first job\n",
    "try:\n",
    "    first_job = driver.find_element(By.CLASS_NAME, 'base-search-card')\n",
    "    first_job.click()\n",
    "    time.sleep(5)  # Wait for job description to load\n",
    "\n",
    "    # Get the updated page source\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Extract job title\n",
    "    title_element = soup.find('h1', class_='top-card-layout__title')\n",
    "    job_title = title_element.get_text(strip=True) if title_element else \"N/A\"\n",
    "\n",
    "    # Extract company name\n",
    "    company_element = soup.find('a', class_='top-card-layout__second-subline')\n",
    "    company_name = company_element.get_text(strip=True) if company_element else \"N/A\"\n",
    "\n",
    "    # Extract job description\n",
    "    driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "    description_element = soup.find('div', class_='show-more-less-html__markup')\n",
    "    job_description = description_element.get_text(\" \", strip=True) if description_element else \"N/A\"\n",
    "\n",
    "    # Print the extracted details\n",
    "    job_data = {\n",
    "        'Job Title': job_title,\n",
    "        'Company': company_name,\n",
    "        'Description': job_description\n",
    "    }\n",
    "\n",
    "    print(job_data)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Close browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#more than 1 job\n",
    "\n",
    "# Initialize the driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Open LinkedIn job search page\n",
    "job_search_url = \"https://www.linkedin.com/jobs/search/?keywords=software%20engineer\"\n",
    "driver.get(job_search_url)\n",
    "time.sleep(10)  \n",
    "\n",
    "# Scroll to load jobs\n",
    "for _ in range(3):\n",
    "    driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(3)\n",
    "\n",
    "jobs_list = []\n",
    "\n",
    "job_count = 0\n",
    "while job_count < 20:\n",
    "    try:\n",
    "        job_cards = driver.find_elements(By.CLASS_NAME, 'base-search-card')\n",
    "        \n",
    "        if len(job_cards) > job_count:\n",
    "            job_cards[job_count].click()  \n",
    "            time.sleep(5)  \n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Extract job title\n",
    "            title_element = soup.find('h1', class_='top-card-layout__title')\n",
    "            job_title = title_element.get_text(strip=True) if title_element else \"N/A\"\n",
    "\n",
    "            # Extract company name\n",
    "            company_element = soup.find('a', class_='top-card-layout__second-subline')\n",
    "            company_name = company_element.get_text(strip=True) if company_element else \"N/A\"\n",
    "\n",
    "            # Extract job description\n",
    "            driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "            description_element = soup.find('div', class_='show-more-less-html__markup')\n",
    "            job_description = description_element.get_text(\" \", strip=True) if description_element else \"N/A\"\n",
    "\n",
    "            jobs_list.append({\n",
    "                'Job Title': job_title,\n",
    "                'Company': company_name,\n",
    "                'Description': job_description\n",
    "            })\n",
    "\n",
    "            job_count += 1  \n",
    "            print(job_count)\n",
    "            driver.back()\n",
    "            time.sleep(3)  \n",
    "        else:\n",
    "            break  \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        break  \n",
    "df_2 = pd.DataFrame(jobs_list)\n",
    "\n",
    "# Close browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv(\"software.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('software.csv')\n",
    "df2 = pd.read_csv('data_scientist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.concat([df1, df2], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   35 non-null     int64  \n",
      " 1   Job Title    35 non-null     object \n",
      " 2   Company      0 non-null      float64\n",
      " 3   Description  35 non-null     object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0','Company'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('job_scrapped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
